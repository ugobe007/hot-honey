# ðŸ”¥ INTELLIGENT SCRAPER - Complete Guide

## What It Does

**Automatically scrapes and saves:**
- ðŸ’¼ **VCs & Angel Groups** â†’ investors table
- ðŸš€ **Startups** â†’ discovered_startups table  
- ðŸ“° **News & Trends** â†’ Extracted and logged

**Uses OpenAI to intelligently:**
- Detect content type automatically
- Extract structured data
- Skip duplicates
- Handle any webpage format

---

## ðŸš€ Quick Start

### 1. Single URL Scraping
```bash
# Auto-detect what's on the page
node intelligent-scraper.js https://dealroom.net/blog/top-venture-capital-firms

# Specify target type
node intelligent-scraper.js https://www.bandofangels.com/members investors
node intelligent-scraper.js https://techcrunch.com/startups/ startups
```

### 2. Batch Scraping (Multiple URLs)
```bash
node intelligent-scraper.js --batch \
  https://dealroom.net/blog/top-venture-capital-firms \
  https://www.cbinsights.com/research/best-venture-capital-firms/ \
  https://www.forbes.com/midas-list/
```

### 3. Automated Scraping (All Sources)
```bash
# Scrape everything (takes 30-60 min)
node auto-scrape-all.js all

# Just VCs
node auto-scrape-all.js vcs

# Just Angel Groups
node auto-scrape-all.js angels

# Just Startups
node auto-scrape-all.js startups

# Just News
node auto-scrape-all.js news
```

---

## ðŸ“‹ Configured Sources

### VC Firms (High Priority)
- âœ… Dealroom Top VCs
- âœ… CB Insights Top 100
- âœ… Forbes Midas List
- âœ… TechCrunch Top VCs
- âœ… Crunchbase VC Rankings

### Angel Groups
- âœ… Band of Angels
- âœ… Tech Coast Angels
- âœ… Keiretsu Forum
- âœ… Golden Seeds

### Accelerators
- âœ… Y Combinator Companies
- âœ… Techstars Portfolio
- âœ… 500 Global Portfolio
- âœ… Plug and Play Portfolio

### Startup Discovery
- âœ… Product Hunt
- âœ… TechCrunch Startups
- âœ… Crunchbase Latest
- âœ… AngelList

### News Sources
- âœ… TechCrunch
- âœ… VentureBeat
- âœ… Crunchbase News
- âœ… The Information

---

## ðŸŽ¯ How It Works

### Step 1: Fetch Page
```
ðŸ“„ Fetches webpage with proper headers
âœ… Handles JavaScript-heavy sites
ðŸ”’ Uses realistic browser User-Agent
```

### Step 2: Extract Content
```
ðŸ“ Parses HTML with Cheerio
ðŸ§¹ Removes scripts, styles, navigation
âœ‚ï¸  Extracts main content only
ðŸ“ Limits to 15k chars for OpenAI
```

### Step 3: AI Analysis
```
ðŸ§  Sends content to GPT-4
ðŸŽ¯ Detects: VCs, Startups, News
ðŸ“Š Extracts structured JSON data
âœ… Returns clean, categorized results
```

### Step 4: Save to Database
```
ðŸ’¼ Investors â†’ investors table
ðŸš€ Startups â†’ discovered_startups table
â­ï¸  Skips duplicates automatically
âœ… Reports what was added
```

---

## ðŸ“Š Example Output

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ”¥ INTELLIGENT SCRAPER - Hot Match
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸŒ Scraping: https://dealroom.net/blog/top-venture-capital-firms
ðŸŽ¯ Target: auto

ðŸ“„ Fetching page...
âœ… Page loaded

ðŸ“ Extracting content...
âœ… Extracted 12458 characters

ðŸ§  Analyzing content with OpenAI...

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“Š EXTRACTION RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ’¼ Investors found: 47
ðŸš€ Startups found: 3
ðŸ“° News themes: 2

ðŸ“Œ Key Themes:
   â€¢ Venture capital funding trends in 2024
   â€¢ Top performing VC firms by returns

ðŸ’¼ Saving 47 investors...

  âœ… Tiger Global Management
  âœ… Accel Partners
  âœ… Lightspeed Venture Partners
  â­ï¸  Sequoia Capital - Already exists
  âœ… Insight Partners
  ... (42 more)

ðŸš€ Saving 3 startups...

  âœ… Databricks
  âœ… Stripe
  âœ… Canva

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ¨ SCRAPING COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ’¼ Investors: 44 added, 3 skipped
ðŸš€ Startups: 3 added, 0 skipped
```

---

## ðŸ”§ Advanced Usage

### Add New Sources

Edit `scraping-sources.json`:
```json
{
  "vc_firms": [
    {
      "name": "Your Source Name",
      "url": "https://example.com/vcs",
      "frequency": "monthly",
      "priority": "high"
    }
  ]
}
```

### Custom Scraping Script
```javascript
const scraper = require('./intelligent-scraper');

// Scrape and get results
const result = await scraper.scrape('https://example.com');

if (result.success) {
  console.log(`Added ${result.investors.added} investors`);
  console.log(`Added ${result.startups.added} startups`);
}
```

### Schedule with Cron

Add to PM2:
```bash
pm2 start auto-scrape-all.js --name "auto-scraper" --cron "0 2 * * *"
```

This runs daily at 2 AM.

---

## ðŸ’¡ Pro Tips

### 1. Start Small
```bash
# Test on one source first
node intelligent-scraper.js https://dealroom.net/blog/top-venture-capital-firms

# Then batch scrape
node auto-scrape-all.js vcs
```

### 2. High-Value Sources First
- Focus on "high" priority sources
- These give best ROI for time spent
- Usually 50-100 entities per source

### 3. Rate Limiting
- Script waits 3-5 seconds between requests
- Prevents getting blocked
- Be respectful to source sites

### 4. Review Results
```bash
# Check investors added
node -e "const {createClient} = require('@supabase/supabase-js'); 
  const supabase = createClient(process.env.VITE_SUPABASE_URL, process.env.SUPABASE_SERVICE_KEY);
  supabase.from('investors').select('name').order('created_at', {ascending: false}).limit(20)
    .then(r => console.log(r.data));"

# Check startups discovered
node test-rss-discovery.js
```

### 5. Enrich After Scraping
```bash
# Add more details with OpenAI
node enrich-investor-data.ts
```

---

## ðŸš¨ Troubleshooting

### "Could not parse OpenAI response"
- OpenAI returned non-JSON
- Try again (rare occurrence)
- Check API key is valid

### "HTTP 403 Forbidden"
- Site blocking scrapers
- Try different User-Agent
- May need browser automation (Puppeteer)

### "No investors/startups found"
- Page format not recognized
- Content too short/generic
- Try targeting specific content type

### Timeout Errors
- Site too slow
- Increase timeout in code
- Or skip that source

---

## ðŸ“ˆ Expected Results

### After Full Auto-Scrape:
- **200-500 VCs** added to database
- **100-300 Startups** discovered
- **50-100 Angel Groups** identified
- **Dozens of accelerators** mapped

### Time Required:
- Single URL: ~30 seconds
- Batch (5 URLs): ~3 minutes
- Full auto-scrape: ~30-60 minutes

### Database Growth:
- Before: 46 investors, 51 startups
- After: 300+ investors, 200+ startups

---

## ðŸŽ¯ Recommended Workflow

### Week 1: Foundation
```bash
# Day 1: Top VCs
node auto-scrape-all.js vcs

# Day 2: Angel Groups  
node auto-scrape-all.js angels

# Day 3: Accelerators
node intelligent-scraper.js https://www.ycombinator.com/companies

# Day 4: Enrich
node enrich-investor-data.ts
```

### Ongoing: Maintenance
```bash
# Weekly: New startups
node auto-scrape-all.js startups

# Daily: News (via RSS)
# Already running via PM2!

# Monthly: Refresh VCs
node auto-scrape-all.js vcs
```

---

## ðŸ”¥ Ready to Scale!

Your scraping system can now:
- âœ… Automatically find VCs from any list
- âœ… Discover angel groups
- âœ… Track accelerator portfolios
- âœ… Find trending startups
- âœ… Monitor news and trends
- âœ… Skip duplicates intelligently
- âœ… Run unattended (batch mode)

**Start with:** `node auto-scrape-all.js vcs`
