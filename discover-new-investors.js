#!/usr/bin/env node
/**
 * Discover New Investors
 * Scrapes VC websites from all-vc-urls-combined.txt to find new investors
 */

require('dotenv').config();
const fs = require('fs');
const { execSync } = require('child_process');

const VC_URLS_FILE = './all-vc-urls-combined.txt';
const BATCH_SIZE = 5;  // Process 5 at a time
const DELAY_BETWEEN_BATCHES = 10000;  // 10 seconds between batches

async function main() {
  console.log('\nðŸ”¥ Discovering New Investors from VC Websites\n');
  console.log('â•'.repeat(70));
  
  // Read VC URLs
  if (!fs.existsSync(VC_URLS_FILE)) {
    console.error(`âŒ File not found: ${VC_URLS_FILE}`);
    process.exit(1);
  }
  
  const urls = fs.readFileSync(VC_URLS_FILE, 'utf-8')
    .split('\n')
    .map(line => line.trim())
    .filter(line => line && line.startsWith('http'));
  
  console.log(`ðŸ“‹ Found ${urls.length} VC URLs to scrape\n`);
  
  let totalAdded = 0;
  let totalSkipped = 0;
  let totalErrors = 0;
  
  for (let i = 0; i < urls.length; i += BATCH_SIZE) {
    const batch = urls.slice(i, i + BATCH_SIZE);
    const batchNum = Math.floor(i / BATCH_SIZE) + 1;
    const totalBatches = Math.ceil(urls.length / BATCH_SIZE);
    
    console.log(`\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    console.log(`ðŸ“¦ Batch ${batchNum}/${totalBatches} (URLs ${i+1}-${Math.min(i+BATCH_SIZE, urls.length)})`);
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    
    for (const url of batch) {
      console.log(`\nðŸŒ Scraping: ${url}`);
      
      try {
        // Try team page first (most likely to have investor info)
        const teamUrls = [
          url.replace(/\/$/, '') + '/team',
          url.replace(/\/$/, '') + '/team/',
          url.replace(/\/$/, '') + '/people',
          url.replace(/\/$/, '') + '/about/team',
          url
        ];
        
        let scraped = false;
        for (const tryUrl of teamUrls) {
          try {
            const output = execSync(`node intelligent-scraper.js "${tryUrl}" investors`, {
              stdio: 'pipe',
              encoding: 'utf-8',
              timeout: 60000
            });
            
            // Parse output
            const addedMatch = output.match(/Investors: (\d+) added/);
            const skippedMatch = output.match(/(\d+) skipped/);
            
            if (addedMatch) {
              const added = parseInt(addedMatch[1]);
              const skipped = parseInt(skippedMatch?.[1] || 0);
              
              if (added > 0 || skipped > 0) {
                totalAdded += added;
                totalSkipped += skipped;
                console.log(`   âœ… ${added} new investors, ${skipped} already exist`);
                scraped = true;
                break;
              }
            }
          } catch (err) {
            // Try next URL variant
            continue;
          }
        }
        
        if (!scraped) {
          console.log(`   â­ï¸  No investors found`);
        }
        
      } catch (error) {
        console.log(`   âŒ Error: ${error.message}`);
        totalErrors++;
      }
      
      // Small delay between URLs
      await new Promise(resolve => setTimeout(resolve, 2000));
    }
    
    // Delay between batches
    if (i + BATCH_SIZE < urls.length) {
      console.log(`\nâ¸ï¸  Pausing ${DELAY_BETWEEN_BATCHES/1000} seconds before next batch...`);
      await new Promise(resolve => setTimeout(resolve, DELAY_BETWEEN_BATCHES));
    }
  }
  
  console.log('\n' + 'â•'.repeat(70));
  console.log('ðŸ“ˆ DISCOVERY SUMMARY');
  console.log('â•'.repeat(70));
  console.log(`âœ… New investors added: ${totalAdded}`);
  console.log(`â­ï¸  Already existed: ${totalSkipped}`);
  console.log(`âŒ Errors: ${totalErrors}`);
  console.log(`ðŸ“Š URLs processed: ${urls.length}`);
  console.log('\nâœ¨ Discovery complete!\n');
  console.log('ðŸ’¡ Next: Run bulk-enrich-investors.js to add details');
}

main().catch(error => {
  console.error('Fatal error:', error);
  process.exit(1);
});
