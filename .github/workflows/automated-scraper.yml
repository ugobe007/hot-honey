name: Automated Startup Discovery

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      run_type:
        description: 'Type of run'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - rss_only
          - discovery_only

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  VITE_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  VITE_SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run Automated Scraper
        run: node automated-scraper.js
        env:
          DEBUG: true

      - name: Report Results
        if: always()
        run: |
          echo "## Scraper Run Complete" >> $GITHUB_STEP_SUMMARY
          echo "- Run time: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- Triggered by: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY

  notify-on-failure:
    needs: scrape
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Log failure
        run: |
          echo "Scraper failed at $(date)"
          echo "Check the workflow logs for details"
